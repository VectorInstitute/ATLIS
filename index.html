<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />

  <title>ATLIS ‚Äî From Models to Systems</title>
  <meta name="description" content="Position: Accountable Deployment of Agentic AI Demands Layered, System-Level Interpretability">
  <meta name="keywords" content="ATLIS, interpretability, LLM agents, agentic systems, monitoring, mechanistic interpretability, multi-agent coordination">

  <!-- Open Graph -->
  <meta property="og:title" content="ATLIS ‚Äî From Models to Systems" />
  <meta property="og:description" content="Accountable Deployment of Agentic AI Demands Layered, System-Level Interpretability" />
  <meta property="og:url" content="https://vectorinstitute.github.io/ATLIS/" />
  <meta property="og:type" content="website" />
  <!-- TODO: set a real preview image in your repo and point to it -->
  <!-- <meta property="og:image" content="https://vectorinstitute.github.io/ATLIS/assets/og.png" /> -->
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- Your new stylesheet -->
  <link rel="stylesheet" href="style.css?v=4" />
</head>

<body>
  <a class="skip-link" href="#main">Skip to content</a>

  <header class="site-header" role="banner">
    <div class="wrap header-inner">
      <div class="brand">
        <a class="brand-logo-link" href="https://vectorinstitute.ai" target="_blank" rel="noopener" aria-label="Vector Institute">
          <img class="brand-logo" src="assets/VectorLogo_Black.png" alt="Vector Institute" />
        </a>
      
        <div class="brand-text">
          <div class="brand-title">ATLIS</div>
          <div class="brand-subtitle">System-Centric Interpretability for Agentic AI</div>
        </div>
      </div>

      <nav class="top-nav" aria-label="Primary">
        <a href="#abstract">Abstract</a>
        <a href="#claims">Core claims</a>
        <a href="#figures">Figures</a>
        <a href="#usecase">Use case</a>
        <a href="#cta">Call to action</a>
        <a href="#bibtex">BibTeX</a>
      </nav>
    </div>
  </header>

  <main id="main" class="site-main">
    <!-- HERO -->
    <section class="hero">
      <div class="wrap">
        <div class="hero-center">
          <div class="pill">Transparent AI Paper</div>

          <h1>
            <span class="hero-accent">Position</span>:
            Accountable Deployment of Agentic AI Demands Layered, System-Level Interpretability
          </h1>

          <div class="paper-meta">
            <div><span class="k">Authors:</span>
              Judy Zhu<sup>1</sup>, Dhari Gandhi<sup>1</sup>, Dhanesh Ramachandram<sup>1</sup>, Ahmad Rezaie Mianroodi<sup>1,2</sup>, Shaina Raza<sup>1</sup>, Sedef Akinli Kocak<sup>1</sup>
            </div>
            <div><span class="k">Affiliations:</span> <sup>1</sup>Vector Institute, <sup>2</sup>Dalhousie University</div>
          </div>

          <div class="cta-row">
            <!-- Replace href when public -->
            <a class="btn btn-disabled" href="#" aria-disabled="true" title="Upload the paper PDF to assets/ then link it">üìÑ Paper</a>
            <a class="btn btn-secondary btn-disabled" href="#" aria-disabled="true" title="Coming soon">TechRxiv</a>
            <a class="btn btn-secondary btn-disabled" href="#" aria-disabled="true" title="Coming soon">Code</a>
            <button class="btn btn-secondary" id="copyBibBtn" type="button">üìã Copy BibTeX</button>
          </div>

          <p class="muted" style="margin-top:10px;">
            Links will be enabled once the paper/arXiv/code are public.
          </p>
        </div>

        <!-- SUMMARY CARDS (edit text as you like) -->
        <div class="hero-cards-row" aria-label="Key highlights">
          <div class="card">
            <div class="card-h">Why model-centric breaks</div>
            <div class="card-b">
              Agentic failures emerge from trajectories: planning, tool use, memory updates, and multi-agent coordination over time.
            </div>
          </div>

          <div class="card">
            <div class="card-h">ATLIS = layered stack</div>
            <div class="card-b">
              Behavioral monitoring ‚Üí mechanistic circuits ‚Üí abstraction bridging ‚Üí multi-agent analysis ‚Üí safety & alignment oversight.
            </div>
          </div>

          <div class="card">
            <div class="card-h">Lifecycle integration</div>
            <div class="card-b">
              Pre-deployment baselines, runtime monitoring, incident response, and post-incident learning‚Äîconnected by feedback loops.
            </div>
          </div>
        </div>

        <div class="callout callout-position">
          <div class="callout-icon">üí°</div>
          <div>
            <div class="callout-title">Position</div>
            <p>
              Interpretability for agentic AI must become <strong>system-centric</strong>:
              explain trajectories, responsibility assignment, and lifecycle dynamics‚Äînot only model internals.
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- TEASER (optional; you can delete) -->
    <section class="section">
      <div class="wrap">
        <p class="lead">
          <strong>Agentic AI systems</strong> extend LLMs with planning, tool use, memory, and multi-step control loops.
          ATLIS proposes interpretability that explains system behavior over time‚Äînot just token-level mechanisms.
        </p>
      </div>
    </section>

    <!-- ABSTRACT -->
    <section id="abstract" class="section alt">
      <div class="wrap">
        <h2>Abstract</h2>
        <p class="lead">
          Agentic AI systems extend large language models with planning, tool use, memory, and multi-step control loops, shifting deployment
          from a single predictive model to a behavior-producing system. We argue interpretability has not made this accompanying shift:
          prevailing methods remain model-centric, explaining isolated outputs rather than diagnosing long-horizon plans, tool-mediated actions,
          and multi-agent coordination. This gap limits auditability and accountability because failures emerge from interactions among planning,
          memory updates, delegation, and environmental feedback.
          <strong>We advance the position that interpretability for agentic AI must be system-centric, focusing on trajectories,
          responsibility assignment, and lifecycle dynamics, not only internal model mechanisms.</strong>
          To operationalize this view, we propose the Agentic Trajectory and Layered Interpretability Stack (ATLIS), spanning real-time behavioral
          monitoring, mechanistic analysis, abstraction bridging, multi-agent coordination analysis, and safety and alignment oversight.
        </p>
      </div>
    </section>

    <!-- CORE CLAIMS -->
    <section id="claims" class="section">
      <div class="wrap">
        <h2>Core claims</h2>

        <div class="three-col">
          <div class="card">
            <div class="card-h">Claim 1</div>
            <div class="card-b">
              <strong>Coevolution over reaction.</strong> Embed interpretability into planning, tool use, and memory from the outset.
            </div>
          </div>

          <div class="card">
            <div class="card-h">Claim 2</div>
            <div class="card-b">
              <strong>Layered decomposition.</strong> Diagnose opacity across behavioral, mechanistic, abstraction, multi-agent, and safety layers.
            </div>
          </div>

          <div class="card">
            <div class="card-h">Claim 3</div>
            <div class="card-b">
              <strong>Lifecycle integration.</strong> Interpretability must span pre-deployment audits, runtime monitoring, and incident response.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- FIGURES -->
    <section id="figures" class="section alt">
      <div class="wrap">
        <h2>Figures</h2>
        <p class="muted">Click a figure to open the PDF in a new tab.</p>

        <div class="figure-grid">
          <figure class="figure-card">
            <a class="figure-link" href="assets/ATLIS-framework.pdf" target="_blank" rel="noopener">
              <img
                src="assets/ATLIS-framework_page-0001.jpg"
                alt="ATLIS Framework Overview"
                onerror="this.onerror=null; this.closest('figure').classList.add('img-error'); this.style.display='none';">
            </a>
            <figcaption>
              <strong>ATLIS Framework Overview.</strong>
              ATLIS integrates five interpretability layers across the agent deployment lifecycle, with monitoring refinement and safety/alignment revision loops.
              <span class="nowrap"><a href="assets/ATLIS-framework.pdf" target="_blank" rel="noopener">Open PDF</a></span>
              <div class="img-fallback">
                Couldn‚Äôt load <code>assets/ATLIS-framework_page-0001.jpg</code>. Check filename + capitalization.
              </div>
            </figcaption>
          </figure>

          <figure class="figure-card">
            <a class="figure-link" href="assets/Illustrative%20Example%20Diagram.pdf" target="_blank" rel="noopener">
              <img
                src="assets/Illustrative%20Example%20Diagram_page-0001.jpg"
                alt="Illustrative Case Study Diagram"
                onerror="this.onerror=null; this.closest('figure').classList.add('img-error'); this.style.display='none';">
            </a>
            <figcaption>
              <strong>Illustrative Case Study.</strong>
              Illustrative example of using ATLIS for a clinical workflow.
              <span class="nowrap"><a href="assets/Illustrative%20Example%20Diagram.pdf" target="_blank" rel="noopener">Open PDF</a></span>
              <div class="img-fallback">
                Couldn‚Äôt load <code>assets/Illustrative%20Example%20Diagram_page-0001.jpg</code>. Check spaces + capitalization.
              </div>
            </figcaption>
          </figure>
        </div>
      </div>
    </section>

    <!-- USE CASE -->
    <section id="usecase" class="section">
      <div class="wrap">
        <h2>Use Case: Palliative Care Referral</h2>
        
        <div class="usecase-content">
          <!-- Failure & Solution Text -->
          <div class="usecase-text">
            <div class="usecase-block">
              <h3>üî¥ The Concrete Failure</h3>
              <p>
                Consider a hospital deploying an agentic system for palliative care referral across two disease sites: lung and gastrointestinal (GI) cancer. 
                Despite identical referral criteria and subagent components, the lung site begins referring patients <strong>later</strong> than GI for matched risk profiles.
              </p>
              <p>
                In one system, short-term symptom improvement stored in memory delays escalation; in the other, accumulated hospitalizations trigger earlier referral. 
                The divergence emerges only over time, due to differences in how longitudinal evidence is stored and propagated through monitoring and planning.
              </p>
              <p class="muted" style="font-style:italic;">
                <strong>Why model-centric methods fail:</strong> Feature attribution (SHAP, Integrated Gradients) explains individual predictions, but the divergence arises from longitudinal interactions between monitoring, memory, planning, and referral timing.
              </p>
            </div>

            <div class="usecase-block">
              <h3>üü¢ How ATLIS Surfaces the Divergence</h3>
              <p>
                ATLIS surfaces this drift <strong>before</strong> it causes harm. <strong>Layer 1</strong> flags a systematic delay in lung referrals relative to GI for comparable patients.
                It then traces the root cause through <strong>Layers 2‚Äì4</strong> using inter-agent coordination signals and mechanistic differences.
              </p>
              <p>
                <strong>Layer 3</strong> maps differences in symptom vs. hospitalization weighting to divergent clinical reasoning pathways, while <strong>Layer 5</strong> evaluates whether referral timing remains within prescribed safety bounds and escalates borderline cases for human-in-the-loop clinician review.
              </p>
              <p>
                Because ATLIS is embedded across the deployment lifecycle, findings feed back into updated simulations (pre-deployment), refined runtime baselines (operations), and recalibrated orchestration policies (post-incident learning).
              </p>
            </div>
          </div>

          <!-- Cyclical Diagram -->
          <div class="usecase-diagram">
            <div class="layer-cycle">
              <div class="cycle-title">ATLIS Layers Applied</div>
              <div class="cycle-ring">
                <div class="layer-node layer-1" data-layer="1">
                  <span class="layer-num">1</span>
                  <span class="layer-name">Behavioral Monitoring</span>
                  <span class="layer-desc">Flag referral delays</span>
                </div>
                <div class="layer-connector c1-2">‚Üí</div>
                <div class="layer-node layer-2" data-layer="2">
                  <span class="layer-num">2</span>
                  <span class="layer-name">Mechanistic Analysis</span>
                  <span class="layer-desc">Trace internal circuits</span>
                </div>
                <div class="layer-connector c2-3">‚Üí</div>
                <div class="layer-node layer-3" data-layer="3">
                  <span class="layer-num">3</span>
                  <span class="layer-name">Abstraction Bridging</span>
                  <span class="layer-desc">Map reasoning pathways</span>
                </div>
                <div class="layer-connector c3-4">‚Üí</div>
                <div class="layer-node layer-4" data-layer="4">
                  <span class="layer-num">4</span>
                  <span class="layer-name">Multi-Agent Analysis</span>
                  <span class="layer-desc">Analyze coordination</span>
                </div>
                <div class="layer-connector c4-5">‚Üí</div>
                <div class="layer-node layer-5" data-layer="5">
                  <span class="layer-num">5</span>
                  <span class="layer-name">Safety & Alignment</span>
                  <span class="layer-desc">Validate & escalate</span>
                </div>
              </div>
              <div class="cycle-feedback">
                <span class="feedback-arrow">‚Ü∫</span>
                <span class="feedback-text">Continuous feedback loop across lifecycle stages</span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- CALL TO ACTION -->
    <section id="cta" class="section alt">
      <div class="wrap">
        <h2>Call to Action</h2>

        <!-- Research Priorities -->
        <h3 class="subsection-title">üî¨ Research Priorities</h3>
        <div class="action-grid">
          <div class="action-card">
            <div class="action-header">
              <div class="action-icon">üß≠</div>
              <h3>System-level attribution</h3>
            </div>
            <ul class="bullets">
              <li>Trace plans, memory reads/writes, tool calls, and delegation across time.</li>
              <li>Assign responsibility within multi-component systems.</li>
            </ul>
          </div>

          <div class="action-card">
            <div class="action-header">
              <div class="action-icon">üìà</div>
              <h3>Scalable runtime interpretability</h3>
            </div>
            <ul class="bullets">
              <li>Continuous lightweight monitoring.</li>
              <li>Risk-aware escalation to deeper analysis when anomalies occur.</li>
            </ul>
          </div>

          <div class="action-card">
            <div class="action-header">
              <div class="action-icon">üß™</div>
              <h3>Benchmarks & infrastructure</h3>
            </div>
            <ul class="bullets">
              <li>Trajectory datasets + logging schemas.</li>
              <li>Multi-agent evaluation protocols.</li>
            </ul>
          </div>
        </div>

        <!-- Broader Implications -->
        <h3 class="subsection-title" style="margin-top: 36px;">üåê Broader Implications</h3>
        <div class="action-grid">
          <div class="action-card impl-card">
            <div class="action-header">
              <div class="action-icon">üë©‚Äçüíª</div>
              <h3>For Practitioners</h3>
            </div>
            <ul class="bullets">
              <li>Adopt layered monitoring from day one‚Äînot as an afterthought.</li>
              <li>Design agent architectures with interpretability hooks at each component.</li>
              <li>Establish incident response workflows that leverage trajectory logs.</li>
            </ul>
          </div>

          <div class="action-card impl-card">
            <div class="action-header">
              <div class="action-icon">‚öñÔ∏è</div>
              <h3>For Regulators</h3>
            </div>
            <ul class="bullets">
              <li>Require system-level audit trails, not just model cards.</li>
              <li>Define accountability standards for multi-agent deployments.</li>
              <li>Mandate human-in-the-loop escalation for high-stakes decisions.</li>
            </ul>
          </div>

          <div class="action-card impl-card">
            <div class="action-header">
              <div class="action-icon">üè¢</div>
              <h3>For Organizations</h3>
            </div>
            <ul class="bullets">
              <li>Invest in interpretability infrastructure alongside capability development.</li>
              <li>Build cross-functional teams spanning ML, systems, and domain expertise.</li>
              <li>Treat post-incident learning as a continuous improvement process.</li>
            </ul>
          </div>
        </div>
      </div>
    </section>

    <!-- BIBTEX -->
    <section class="section alt" id="bibtex">
      <div class="wrap">
        <h2>BibTeX</h2>
        <pre class="bib" id="bibBlock"><code>@inproceedings{atlis2026position,
  title     = {Position: Accountable Deployment of Agentic AI Demands Layered, System-Level Interpretability},
  author    = {Zhu, Judy and Gandhi, Dhari and Ramachandram, Dhanesh and Rezaie Mianroodi, Ahmad and Raza, Shaina and Kocak, Sedef Akinli},
  booktitle = {TBD},
  year      = {2026},
  note      = {Under review}
}</code></pre>
        <p class="fineprint">Tip: keep venue as ‚ÄúTBD‚Äù until de-anonymization / acceptance.</p>
      </div>
    </section>

    <footer class="site-footer">
      <div class="wrap footer-inner">
        <div>
          <div class="footer-title">ATLIS</div>
          <div class="footer-muted">From Models to Systems ‚Ä¢ <span id="year"></span></div>
        </div>
        <div class="footer-links">
          <a href="#abstract">Abstract</a>
          <a href="#figures">Figures</a>
          <a href="#bibtex">BibTeX</a>
          <a href="https://github.com/vectorinstitute/ATLIS" target="_blank" rel="noopener">GitHub</a>
        </div>
      </div>
    </footer>
  </main>

  <script src="./main.js"></script>
</body>
</html>
