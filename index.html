<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Position: From Models to Systems — ATLIS</title>
  <meta name="description" content="ICML position paper page: Agentic Trajectory and Layered Interpretability Stack (ATLIS)" />
  <link rel="stylesheet" href="styles.css" />
</head>

<body>
  <header class="site-header">
    <div class="container">
      <p class="kicker">ICML Position Paper</p>
      <h1 class="title">
        Position: As we move from models to systems, we need and should use the
        Agentic Trajectory and Layered Interpretability Stack (ATLIS)
      </h1>

      <p class="authors">
        Judy Zhu · Dhari Gandhi · Ahmad Rezaie Mianroodi · Dhanesh Ramachandran · Shaina Raza · Sedef Akinli Kocak
      </p>

      <div class="links">
        <a class="btn disabled" href="#" aria-disabled="true" title="Coming soon">Paper (coming soon)</a>
        <a class="btn disabled" href="#" aria-disabled="true" title="Coming soon">arXiv (coming soon)</a>
        <a class="btn disabled" href="#" aria-disabled="true" title="Coming soon">Github (coming soon)</a>
      </div>

      <p class="note">
        *Links will be enabled once the PDF/arXiv is available.
      </p>
    </div>
  </header>

  <nav class="toc" aria-label="Section navigation">
    <div class="container toc-inner">
      <a href="#abstract">Abstract</a>
      <a href="#introduction">Introduction</a>
      <a href="#position">Position</a>
      <a href="#counterarguments">Counterarguments</a>
      <a href="#framework">Conceptual Framework</a>
      <a href="#case-study">Illustrative Case Study</a>
      <a href="#call-to-action">Call to Action</a>
      <a href="#discussion">Discussion and Limitations</a>
      <a href="#bibtex">BibTeX</a>
    </div>
  </nav>

  <main class="container">
    <section id="abstract" class="section">
      <h2>Abstract</h2>
      <p class="muted">
        Agentic AI systems extend large language models with planning, tool use, memory, and multi-step control loops, shifting deployment from a single predictive model to a behavior-producing system. We argue interpretability has not made this accompanying shift: prevailing methods remain model-centric, explaining isolated outputs rather than diagnosing long-horizon plans, tool-mediated actions, and multi-agent coordination. This gap limits auditability and accountability because failures emerge from interactions among planning, memory updates, delegation, and environmental feedback. \textbf{We advance the position that interpretability for agentic AI must be system-centric, focusing on trajectories, responsibility assignment, and lifecycle dynamics, not only internal model mechanisms.} To operationalize this view, we propose the Agentic Trajectory and Layered Interpretability Stack (ATLIS), spanning real-time behavioral monitoring, mechanistic analysis, abstraction bridging, multi-agent coordination analysis, and safety and alignment oversight. We map these layers to a five-stage agent lifecycle and motivate risk-aware activation of high-cost analyses during incidents alongside continuous low-overhead monitoring in production.
      </p>
    </section>

    <section id="introduction" class="section">
      <h2>Introduction</h2>
      <p class="muted">
        (Add introduction here.)
      </p>
    </section>

    <section id="position" class="section">
      <h2>Position</h2>
      <p class="muted">
        The interpretability field is solving the wrong problem for the agentic era. Current methods explain how individual models compute outputs but cannot explain why an agent selected a particular plan, how coordination failed, or where accountability lies. We argue three points: (1) interpretability methods must co-evolve with agentic capabilities rather than follow them, embedding transparency into planning, tool use, and memory from the outset; (2) agentic opacity occurs at distinct layers—behavioral, mechanistic, coordination, and safety, each requiring tailored methods; and (3) interpretability must integrate across the full agent development lifecycle rather than serve as a one-time audit.
      </p>

      <div class="callout">
        <h3>Core Claims (placeholders)</h3>
        <ol>
          <li><strong>Coevolution over reaction.</strong> …</li>
          <li><strong>Layered decomposition.</strong> …</li>
          <li><strong>Lifecycle integration.</strong> …</li>
        </ol>
      </div>
    </section>

    <section id="counterarguments" class="section">
      <h2>Alternate Positions and Counterarguments</h2>
      <p class="muted">
        (Add Counterpositions here)
      </p>
    </section>

    <section id="framework" class="section">
      <h2>Conceptual Framework</h2>
      <p class="muted">
        (Briefly introduce ATLIS and the lifecycle + layered stack figure)
      </p>

      <figure class="figure">
        <object data="assets/ATLIS-framework.pdf" type="application/pdf" class="pdf">
          <p class="muted">
            Your browser can’t display PDFs inline.
            <a href="assets/ATLIS-framework.pdf">Open the figure PDF</a>.
          </p>
        </object>
        <figcaption>
          ATLIS (Agentic Trajectory & Layered Interpretability Stack) is an agentic deployment lifecycle and integrated interpretability stack for Agentic AI systems. This framework integrates five interpretability layers across the Agentic AI system lifecycle: (1) Real-Time Behavioral Monitoring tracks observable agent actions; (2) Mechanistic Circuit Analysis examines internal model representations; (3) Abstraction-Level Bridging connects low-level circuits to high-level reasoning; (4) Multi-Agent Analysis evaluates coordination dynamics; and (5) Safety and Alignment ensures adherence to predefined objectives. It is important to highlight that the framework incorporates two loops: blue arrows denote the monitoring refinement feedback loop, while orange arrows denote the safety and alignment revision loop. Computational overhead ranges from low (Layer 1 continuous monitoring) to high (Layer 2 full circuit extraction during incident response).
        </figcaption>
      </figure>
    </section>

    <section id="case-study" class="section">
      <h2>Illustrative Case Study</h2>
      <p class="muted">
        Add illustrative Hospital Use Case.
      </p>

      <figure class="figure">
        <img src="assets/ICML Illustrative Example Diagram.pdf" alt="Illustrative Example: Palliative-Care Referral" />
        <figcaption>
          Illustrative Example of using ATLIS for disease diagnosis.
      </figure>
    </section>

    <section id="call-to-action" class="section">
      <h2>Call to Action</h2>
      <ul class="muted">
        <li>System-Level Attribution and Tracing.</li>
        <li>Scalable Runtime Interpretability.</li>
        <li>Benchmarks and Evaluation Infrastructure.</li>
      </ul>
    </section>

    <section id="discussion" class="section">
      <h2>Discussion and Limitations</h2>
      <p class="muted">
        Add discussion implementation limitations with ATLIS.
      </p>
    </section>

    <section id="bibtex" class="section">
      <h2>BibTeX</h2>
      <pre class="bibtex"><code>@inproceedings{atlIs2026position,
  title     = {Position: As we move from models to systems, we need and should use the Agentic Trajectory and Layered Interpretability Stack (ATLIS)},
  author    = {Zhu, Judy and Gandhi, Dhari and Mianroodi, Ahmad Rezaie and Ramachandran, Dhanesh and Raza, Shaina and Kocak, Sedef Akinli},
  booktitle = {International Conference on Machine Learning (ICML) Position Paper},
  year      = {2026},
  note      = {Under review}
}</code></pre>

      <p class="muted small">
        Update venue/year/status when submission details are finalized.
      </p>
    </section>

    <footer class="footer">
      <p class="muted small">
        © <span id="year"></span> ATLIS authors. Built for GitHub Pages.
      </p>
    </footer>
  </main>

  <script>
    document.getElementById("year").textContent = new Date().getFullYear();
    // Make disabled buttons non-clickable
    document.querySelectorAll(".btn.disabled").forEach(a => a.addEventListener("click", (e) => e.preventDefault()));
  </script>
</body>
</html>
